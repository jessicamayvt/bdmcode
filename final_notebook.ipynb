{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will analyze NBM data and answer the following questions: \n",
    "1. How many unique BSLs are there in the latest version of each major release in Virginia?\n",
    "2. How many ISPs provide service in Tennessee?\n",
    "3. How many unserved BSLs are in Virginia in the latest version of each major release? An “unserved” BSL is one that does not have service exceeding 25Mbps download speed and 3Mbps upload speed from any ISP, ignoring ISPs that provide service to the BSL using any form of satellite Internet or *unlicensed* fixed wireless technology. They must also have either residential or “both” service and the service must be classified as “low latency”. Hint: you’ll want to filter based on technology code, download and upload speeds, business/residential code (values R and X), as well as the low latency flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import depednecies and read files. \n",
    "from get_parquet  import *\n",
    "from categorize_bsl import *\n",
    "from get_df import *\n",
    "import concurrent.futures\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from libnbm import *\n",
    "import duckdb\n",
    "DATA_ROOT = '/playpen/data/nbm'\n",
    "DATA_ROOT_SLICE = \"/playpen/data/nbm/preprocessed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1: How many unique BSLs are there in the latest version of each major release in Virginia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the number of unique BSLs in the latest version of each major release in Virginia: \n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "/home/playpen/data/nbm_evolution/data/nbm/bdc_single_file/20220630/20240510/bdc_51_single_nbm.parquet",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 246, in _process_worker\n    r = call_item.fn(*call_item.args, **call_item.kwargs)\n  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 205, in _process_chunk\n    return [fn(*args) for args in chunk]\n  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 205, in <listcomp>\n    return [fn(*args) for args in chunk]\n  File \"/tmp/ipykernel_886260/4290575606.py\", line 19, in get_bsl_count\n    df = return_df(major, major_minor_dict[major], 51)\n  File \"/tmp/ipykernel_886260/4290575606.py\", line 15, in return_df\n    table = pyarrow_pq.read_pandas(f\"{DATA_BASEDIR}/{major}/{minor}/bdc_{str(fips_code).zfill(2)}_single_nbm.parquet\", use_threads=True)\n  File \"/home/jessicamay/.venv/lib/python3.10/site-packages/pyarrow/parquet/core.py\", line 1858, in read_pandas\n    return read_table(\n  File \"/home/jessicamay/.venv/lib/python3.10/site-packages/pyarrow/parquet/core.py\", line 1793, in read_table\n    dataset = ParquetDataset(\n  File \"/home/jessicamay/.venv/lib/python3.10/site-packages/pyarrow/parquet/core.py\", line 1371, in __init__\n    self._dataset = ds.dataset(path_or_paths, filesystem=filesystem,\n  File \"/home/jessicamay/.venv/lib/python3.10/site-packages/pyarrow/dataset.py\", line 794, in dataset\n    return _filesystem_dataset(source, **kwargs)\n  File \"/home/jessicamay/.venv/lib/python3.10/site-packages/pyarrow/dataset.py\", line 476, in _filesystem_dataset\n    fs, paths_or_selector = _ensure_single_source(source, filesystem)\n  File \"/home/jessicamay/.venv/lib/python3.10/site-packages/pyarrow/dataset.py\", line 441, in _ensure_single_source\n    raise FileNotFoundError(path)\nFileNotFoundError: /home/playpen/data/nbm_evolution/data/nbm/bdc_single_file/20220630/20240510/bdc_51_single_nbm.parquet\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m     result \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39mmap(get_bsl_count, majors)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHere are the number of unique BSLs in the latest version of each major release in Virginia: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m result: \n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(r)\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/process.py:575\u001b[0m, in \u001b[0;36m_chain_from_iterable_of_lists\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_chain_from_iterable_of_lists\u001b[39m(iterable):\n\u001b[1;32m    570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;124;03m    Specialized implementation of itertools.chain.from_iterable.\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;124;03m    Each item in *iterable* should be a list.  This function is\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;124;03m    careful not to keep references to yielded objects.\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m    576\u001b[0m         element\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m element:\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:621\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:319\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 319\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    321\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: /home/playpen/data/nbm_evolution/data/nbm/bdc_single_file/20220630/20240510/bdc_51_single_nbm.parquet"
     ]
    }
   ],
   "source": [
    "majors = [20220630, 20221231, 20230630, 20231231, 20240630]\n",
    "minors = [20240510, 20241104, 20250210, 20250201, 20250218]\n",
    "major_minor_dict = dict(zip(majors, minors))\n",
    "\n",
    "# def return_df(major, minor, fips_code):\n",
    "#     DATA_BASEDIR = '/home/playpen/data/nbm_evolution/data/nbm/bdc_single_file'\n",
    "#     columns_to_read = [\"location_id\", \"max_advertised_download_speed\", \n",
    "#                        \"max_advertised_upload_speed\", \"technology\", \n",
    "#                        \"low_latency\", \"business_residential_code\"]\n",
    "#     table = pyarrow_pq.read_pandas(f\"{DATA_BASEDIR}/{major}/{minor}/bdc_{str(fips_code).zfill(2)}_single_nbm.parquet\", columns = columns_to_read, use_threads=True)\n",
    "#     return table.to_pandas()\n",
    "\n",
    "def return_df(major, minor, fips_code):\n",
    "    DATA_BASEDIR = '/home/playpen/data/nbm_evolution/data/nbm/bdc_single_file'\n",
    "    table = pyarrow_pq.read_pandas(f\"{DATA_BASEDIR}/{major}/{minor}/bdc_{str(fips_code).zfill(2)}_single_nbm.parquet\", use_threads=True)\n",
    "    return table.to_pandas()\n",
    "\n",
    "def get_bsl_count(major):\n",
    "    df = return_df(major, major_minor_dict[major], 51)\n",
    "    unique_locs_count = df['location_id'].nunique()\n",
    "    return(f\"For major release {major} and minor release {major_minor_dict[major]}, there are {unique_locs_count} unique BSLs\")\n",
    "\n",
    "result = []\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=10) as executor:\n",
    "    result = executor.map(get_bsl_count, majors)\n",
    "\n",
    "print(\"Here are the number of unique BSLs in the latest version of each major release in Virginia: \\n\")\n",
    "for r in result: \n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DUCK DB QUESTION 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the number of unique BSLs in the latest version of each major release in Virginia: \n",
      "\n",
      "For major release 20220630 and minor release 20240510, there are 2840311 unique BSLs\n",
      "For major release 20221231 and minor release 20241104, there are 2914429 unique BSLs\n",
      "For major release 20230630 and minor release 20250210, there are 2920197 unique BSLs\n",
      "For major release 20231231 and minor release 20250201, there are 2907830 unique BSLs\n",
      "For major release 20240630 and minor release 20250304, there are 2911038 unique BSLs\n"
     ]
    }
   ],
   "source": [
    "majors = [20220630, 20221231, 20230630, 20231231, 20240630]\n",
    "minors = [20240510, 20241104, 20250210, 20250201, 20250304]\n",
    "major_minor_dict = dict(zip(majors, minors))\n",
    "\n",
    "def get_bsl_count(major):\n",
    "    minor = major_minor_dict[major]\n",
    "    fips_code = 51  # Virginia\n",
    "    file_path = os.path.join(DATA_ROOT_SLICE, f\"nbm_{str(major)}_{str(minor)}_zstd.parquet\")\n",
    "    \n",
    "    # Query to count unique location_ids\n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "        COUNT(DISTINCT location_id) AS unique_location_ids\n",
    "    FROM '{file_path}'\n",
    "    WHERE state_fips = {fips_code}\n",
    "    \"\"\"\n",
    "    result = duckdb.query(query).fetchall()\n",
    "    unique_location_ids = result[0][0]\n",
    "    \n",
    "    return f\"For major release {major} and minor release {minor}, there are {unique_location_ids} unique BSLs\"\n",
    "\n",
    "\n",
    "result = []\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=10) as executor:\n",
    "    result = executor.map(get_bsl_count, majors)\n",
    "\n",
    "print(\"Here are the number of unique BSLs in the latest version of each major release in Virginia: \\n\")\n",
    "for r in result: \n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2: How many ISPs provide service in Tennessee?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the number of unique ISPs in the latest version of each major release in Tennessee: \n",
      "\n",
      "For major release 20220630 and minor release 20240510, there are 96 unique ISPs\n",
      "For major release 20221231 and minor release 20241104, there are 98 unique ISPs\n",
      "For major release 20230630 and minor release 20250210, there are 94 unique ISPs\n",
      "For major release 20231231 and minor release 20250201, there are 99 unique ISPs\n",
      "For major release 20240630 and minor release 20250304, there are 102 unique ISPs\n"
     ]
    }
   ],
   "source": [
    "majors = [20220630, 20221231, 20230630, 20231231, 20240630]\n",
    "minors = [20240510, 20241104, 20250210, 20250201, 20250304]\n",
    "major_minor_dict = dict(zip(majors, minors))\n",
    "\n",
    "def count_brand_name(major):\n",
    "    df = parquet_to_df(major, major_minor_dict[major], 47)\n",
    "    return f\"For major release {major} and minor release {major_minor_dict[major]}, there are {df['provider_id'].nunique()} unique ISPs\"\n",
    "\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=10) as executor:\n",
    "    result = executor.map(count_brand_name, majors)\n",
    "\n",
    "print(\"Here are the number of unique ISPs in the latest version of each major release in Tennessee: \\n\")\n",
    "\n",
    "for r in result: \n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DUCK DB QUESTION 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the number of unique ISPs in the latest version of each major release in Tennessee:\n",
      "\n",
      "For major release 20220630 and minor release 20240510, there are 96 unique ISPs in Tennessee.\n",
      "For major release 20221231 and minor release 20241104, there are 98 unique ISPs in Tennessee.\n",
      "For major release 20230630 and minor release 20250210, there are 94 unique ISPs in Tennessee.\n",
      "For major release 20231231 and minor release 20250201, there are 99 unique ISPs in Tennessee.\n",
      "For major release 20240630 and minor release 20250304, there are 102 unique ISPs in Tennessee.\n"
     ]
    }
   ],
   "source": [
    "majors = [20220630, 20221231, 20230630, 20231231, 20240630]\n",
    "minors = [20240510, 20241104, 20250210, 20250201, 20250304]\n",
    "major_minor_dict = dict(zip(majors, minors))\n",
    "\n",
    "def count_brand_name(major):\n",
    "    minor = major_minor_dict[major]\n",
    "    file_path = os.path.join(DATA_ROOT_SLICE, f\"nbm_{str(major)}_{str(minor)}_zstd.parquet\")\n",
    "\n",
    "    query = f\"\"\"\n",
    "    SELECT COUNT(DISTINCT provider_id) AS unique_isps\n",
    "    FROM '{file_path}'\n",
    "    WHERE state_fips = 47\n",
    "    \"\"\"\n",
    "    \n",
    "    result = duckdb.query(query).fetchall()\n",
    "    unique_isps = result[0][0]\n",
    "    \n",
    "    return f\"For major release {major} and minor release {minor}, there are {unique_isps} unique ISPs in Tennessee.\"\n",
    "\n",
    "# Run in parallel\n",
    "result = []\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=10) as executor:\n",
    "    result = executor.map(count_brand_name, majors)\n",
    "\n",
    "print(\"Here are the number of unique ISPs in the latest version of each major release in Tennessee:\\n\")\n",
    "\n",
    "for r in result: \n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3: How many unserved BSLs are in Virginia in the latest version of each major release? An “unserved” BSL is one that does not have service exceeding 25Mbps download speed and 3Mbps upload speed from any ISP, ignoring ISPs that provide service to the BSL using any form of satellite Internet or unlicensed fixed wireless technology. They must also have either residential or “both” service and the service must be classified as “low latency”. Hint: you’ll want to filter based on technology code, download and upload speeds, business/residential code (values R and X), as well as the low latency flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the number of unserved BSLs in the latest version of each major release in Virginia: \n",
      "\n",
      "For major release 20220630 and minor release 20240510, there are 367789 unserved BSLs\n",
      "For major release 20221231 and minor release 20241104, there are 373066 unserved BSLs\n",
      "For major release 20230630 and minor release 20250210, there are 368998 unserved BSLs\n",
      "For major release 20231231 and minor release 20250201, there are 305541 unserved BSLs\n",
      "For major release 20240630 and minor release 20250218, there are 276281 unserved BSLs\n"
     ]
    }
   ],
   "source": [
    "# Define directory and mappings\n",
    "DATA_BASEDIR = \"/home/playpen/data/nbm_evolution/data/nbm/bdc_single_file\"\n",
    "majors = [20220630, 20221231, 20230630, 20231231, 20240630]\n",
    "minors = [20240510, 20241104, 20250210, 20250201, 20250218]\n",
    "major_minor_dict = dict(zip(majors, minors))\n",
    "\n",
    "technology_codes = {\n",
    "    10: \"Copper Wire\",\n",
    "    40: \"Coaxial Cable / HFC\",\n",
    "    50: \"Optical Carrier / Fiber to the Premises\",\n",
    "    60: \"Geostationary Satellite\",\n",
    "    61: \"Non-geostationary Satellite\",\n",
    "    70: \"Unlicensed Terrestrial Fixed Wireless\",\n",
    "    71: \"Licensed Terrestrial Fixed Wireless\",\n",
    "    72: \"Licensed-by-Rule Terrestrial Fixed Wireless\",\n",
    "    0: \"Other\"\n",
    "}\n",
    "\n",
    "valid_technologies = [50, 40, 10, 71]\n",
    "valid_res_codes = [\"X\", \"R\"]\n",
    "\n",
    "def unserved_per_major(major):\n",
    "    df = parquet_to_df(major, major_minor_dict[major], 51)\n",
    "    new_df = get_best_status(df)\n",
    "    unserved_count = new_df['status'].value_counts().get('unserved', 0)\n",
    "    return (f\"For major release {major} and minor release {major_minor_dict[major]}, there are {unserved_count} unserved BSLs\")\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=10) as executor:\n",
    "    result = executor.map(unserved_per_major, majors)\n",
    "\n",
    "print(\"Here are the number of unserved BSLs in the latest version of each major release in Virginia: \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the number of unserved BSLs in the latest version of each major release in Virginia:\n",
      "\n",
      "For major release 20220630 and minor release 20240510, there are 340940 unserved BSLs\n",
      "For major release 20221231 and minor release 20241104, there are 290628 unserved BSLs\n",
      "For major release 20230630 and minor release 20250210, there are 254064 unserved BSLs\n",
      "For major release 20231231 and minor release 20250201, there are 217991 unserved BSLs\n",
      "For major release 20240630 and minor release 20250218, there are 158022 unserved BSLs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "majors = [20220630, 20221231, 20230630, 20231231, 20240630]\n",
    "minors = [20240510, 20241104, 20250210, 20250201, 20250218]\n",
    "major_minor_dict = dict(zip(majors, minors))\n",
    "DATA_ROOT_SLICE = \"/playpen/data/nbm/preprocessed\"\n",
    "\n",
    "\n",
    "technology_codes = {\n",
    "    10: \"Copper Wire\",\n",
    "    40: \"Coaxial Cable / HFC\",\n",
    "    50: \"Optical Carrier / Fiber to the Premises\",\n",
    "    60: \"Geostationary Satellite\",\n",
    "    61: \"Non-geostationary Satellite\",\n",
    "    70: \"Unlicensed Terrestrial Fixed Wireless\",\n",
    "    71: \"Licensed Terrestrial Fixed Wireless\",\n",
    "    72: \"Licensed-by-Rule Terrestrial Fixed Wireless\",\n",
    "    0: \"Other\"\n",
    "}\n",
    "\n",
    "valid_technologies = [50, 40, 10, 71, 72]\n",
    "invalid_technologies = [60, 61, 0]\n",
    "valid_res_codes = [\"X\", \"R\"]\n",
    "\n",
    "def unserved_per_major(major):\n",
    "    minor = major_minor_dict[major]\n",
    "    file_path = os.path.join(DATA_ROOT_SLICE, f\"nbm_{str(major)}_{str(minor)}_zstd.parquet\")\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    SELECT COUNT(*) AS unserved_count\n",
    "    FROM (\n",
    "        SELECT location_id,\n",
    "            MAX(\n",
    "                CASE\n",
    "                    WHEN max_advertised_download_speed > 100 AND max_advertised_upload_speed > 20 THEN 2\n",
    "                    WHEN max_advertised_download_speed > 25 AND max_advertised_upload_speed > 3 THEN 1\n",
    "                    ELSE 0\n",
    "                END\n",
    "            ) AS status\n",
    "        FROM '{file_path}'\n",
    "        WHERE state_fips = 51\n",
    "          AND technology IN ({','.join(map(str, valid_technologies))})\n",
    "          AND business_residential_code IN ({','.join(f\"'{r}'\" for r in valid_res_codes)})\n",
    "          AND low_latency = 1\n",
    "        GROUP BY location_id\n",
    "    )\n",
    "    WHERE status = 0  -- 0 = unserved\n",
    "    \"\"\"\n",
    "    result = duckdb.query(query).fetchall()\n",
    "    unserved_count = result[0][0]  \n",
    "    return f\"For major release {major} and minor release {major_minor_dict[major]}, there are {unserved_count} unserved BSLs\"\n",
    "\n",
    "\n",
    "# Run in parallel\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=10) as executor:\n",
    "    result = executor.map(unserved_per_major, majors)\n",
    "\n",
    "print(\"Here are the number of unserved BSLs in the latest version of each major release in Virginia:\\n\")\n",
    "\n",
    "for r in result:\n",
    "    print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
